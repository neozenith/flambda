{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebc6b51-3243-4c8f-a376-f0cb2063866a",
   "metadata": {},
   "source": [
    "# NLP Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "584ba113-1553-4958-85a5-b0d77275238a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "# Scientific\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# AWS\n",
    "import awswrangler as wr\n",
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "\n",
    "# HuggingFace\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "# Various Third Party\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bae4e8-5e1d-4150-85dd-c10bb209f708",
   "metadata": {},
   "source": [
    "## Setup Session Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10148cf3-3b61-4559-a58a-8ee0c66f802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://play-projects-joshpeak/nlp-play/sagemaker\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "bucket = os.getenv(\"DEFAULT_BUCKET\")\n",
    "prefix = os.getenv(\"S3_PREFIX\")\n",
    "\n",
    "path_prefix = f\"s3://{bucket}/{prefix}\"\n",
    "\n",
    "boto_session = boto3.Session(profile_name=os.getenv(\"AWS_PROFILE\"), region_name=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "session = sagemaker.Session(boto_session=boto_session, default_bucket=bucket)\n",
    "s3fs = S3FileSystem(session=botocore.session.Session(profile=os.getenv(\"AWS_PROFILE\")))\n",
    "role = os.getenv(\"SAGEMAKER_ARN_ROLE\", None)\n",
    "\n",
    "print(path_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc157a3-2692-4539-9cef-97e632231f74",
   "metadata": {},
   "source": [
    "## Fetch Data from Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5003d5ae-7c57-4b1e-a312-38bd11b2c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dataset = Path(\"./data/transactions.dataset/\")\n",
    "\n",
    "if not cache_dataset.exists():\n",
    "    print(\"Cache miss... fetching...\")\n",
    "    df = wr.athena.read_sql_query(\n",
    "        \"\"\"\n",
    "    SELECT \n",
    "        rule_based_label as label\n",
    "        , description as source\n",
    "    FROM finances.silver_labelled\n",
    "    WHERE rule_based_label not in ('Other')\n",
    "    \"\"\",\n",
    "        \"finances\",\n",
    "        boto3_session=boto_session,\n",
    "    )\n",
    "    ds = Dataset.from_pandas(df)\n",
    "    ds.save_to_disk(str(cache_dataset))\n",
    "\n",
    "transactions_dataset = load_from_disk(str(cache_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c2205f-3e62-4a47-b15a-b14644024828",
   "metadata": {},
   "source": [
    "## Create Train / Test / Validate Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d26350ec-87fa-4a18-8ba0-c34b58c8b80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'source'],\n",
       "        num_rows: 909\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'source'],\n",
       "        num_rows: 102\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_transactions_dataset = transactions_dataset.shuffle().train_test_split(test_size=0.1)\n",
    "train_test_transactions_dataset.cleanup_cache_files()\n",
    "train_test_transactions_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2cc23a-6eee-482a-9aa5-00512d157388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11af5412-3312-4047-9db3-e6b7bb824832",
   "metadata": {},
   "source": [
    "## Export Data to S3 ready for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9be4aac-a929-4362-83e5-6588624904d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://play-projects-joshpeak/nlp-play/sagemaker/transactions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08de9cb9f2b45dfbfca27bd203922f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90499afa086347cb9d7d11aaccf62efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"{path_prefix}/transactions\"\n",
    "print(path)\n",
    "train_test_transactions_dataset.save_to_disk(path, fs=s3fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3176cd54-4416-4515-be56-e371bbd9b0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "770490d4-d9a0-4119-8580-768873b37f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      EnergyAustralia Pty NetBank BPAY Bill Electricity\n",
       "1                             PRICELINE KOTARA KOTARAWAU\n",
       "2                     The Forum Univer EZYPAYID_11900826\n",
       "3                                    WOOLWORTHS MAYFIELD\n",
       "4                       MCDONALDS F3 NORTHBOU JILLIBYWAU\n",
       "                             ...                        \n",
       "97                                        COLES WALLSEND\n",
       "98                      MCDONALDS F3 NORTHBOU JILLIBYWAU\n",
       "99                               OFFICEWORKS NEWCASTLE W\n",
       "100                                CommInsure--148724286\n",
       "101                         CALTEX WYONG PETROL SO WYONG\n",
       "Name: source, Length: 102, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_test_transactions_dataset[\"train\"].to_pandas()\n",
    "df_test = train_test_transactions_dataset[\"test\"].to_pandas()\n",
    "df_test.source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a93f5c-d817-489c-a96b-944d34e92c66",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c2e4ec9-90f3-4e62-9d14-138355177f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cda3700-f685-46d8-b87a-d63894475893",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = (doc for doc in df_test.source if not any([k in doc for k in [\"WOOLWORTHS\", \"COLES\", \"BUNNINGS\"]]))\n",
    "docs_iter = iter(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b32fcaf1-12bb-4870-b47d-cd0ad4fc9377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyAustralia Pty NetBank BPAY Bill Electricity\n",
      "['energy', '##aus', '##tral', '##ia', 'pt', '##y', 'net', '##bank', 'bp', '##ay', 'bill', 'electricity']\n"
     ]
    }
   ],
   "source": [
    "doc = next(docs_iter)\n",
    "print(doc)\n",
    "result = tokenizer.tokenize(doc, return_tensors=\"pt\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1a0de-9e83-42a5-bf3e-0db73495f513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110160d-8f65-41f3-a3ab-89482560a6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
